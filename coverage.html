
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>app: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/dnsoftware/mpm-save-get-shares/cmd/app/main.go (0.0%)</option>
				
				<option value="file1">github.com/dnsoftware/mpm-save-get-shares/config/config.go (81.0%)</option>
				
				<option value="file2">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/clickhouse/share_storage.go (66.7%)</option>
				
				<option value="file3">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/grpc/coin_storage.go (87.5%)</option>
				
				<option value="file4">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/kafka_consumer/shares/consumer.go (92.9%)</option>
				
				<option value="file5">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/postgres/coin_storage.go (100.0%)</option>
				
				<option value="file6">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/postgres/miner_storage.go (91.7%)</option>
				
				<option value="file7">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/ristretto/coin_storage.go (0.0%)</option>
				
				<option value="file8">github.com/dnsoftware/mpm-save-get-shares/internal/adapter/ristretto/miner_storage.go (83.0%)</option>
				
				<option value="file9">github.com/dnsoftware/mpm-save-get-shares/internal/app/app.go (0.0%)</option>
				
				<option value="file10">github.com/dnsoftware/mpm-save-get-shares/internal/dto/share_kafka.go (100.0%)</option>
				
				<option value="file11">github.com/dnsoftware/mpm-save-get-shares/internal/usecase/share/helpers.go (83.3%)</option>
				
				<option value="file12">github.com/dnsoftware/mpm-save-get-shares/internal/usecase/share/normalize_share.go (79.2%)</option>
				
				<option value="file13">github.com/dnsoftware/mpm-save-get-shares/internal/usecase/share/save_share.go (0.0%)</option>
				
				<option value="file14">github.com/dnsoftware/mpm-save-get-shares/internal/usecase/share/usecase.go (100.0%)</option>
				
				<option value="file15">github.com/dnsoftware/mpm-save-get-shares/pkg/kafka_reader/reader.go (0.0%)</option>
				
				<option value="file16">github.com/dnsoftware/mpm-save-get-shares/pkg/kafka_writer/header_carrier.go (11.1%)</option>
				
				<option value="file17">github.com/dnsoftware/mpm-save-get-shares/pkg/kafka_writer/writer.go (91.1%)</option>
				
				<option value="file18">github.com/dnsoftware/mpm-save-get-shares/pkg/logger/logger.go (57.1%)</option>
				
				<option value="file19">github.com/dnsoftware/mpm-save-get-shares/pkg/otel/otel.go (0.0%)</option>
				
				<option value="file20">github.com/dnsoftware/mpm-save-get-shares/pkg/utils/projectdir.go (72.7%)</option>
				
				<option value="file21">github.com/dnsoftware/mpm-save-get-shares/test/testcontainers/kafka.go (75.0%)</option>
				
				<option value="file22">github.com/dnsoftware/mpm-save-get-shares/test/testcontainers/postgres.go (83.3%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">no coverage</span>
				<span class="cov1">low coverage</span>
				<span class="cov2">*</span>
				<span class="cov3">*</span>
				<span class="cov4">*</span>
				<span class="cov5">*</span>
				<span class="cov6">*</span>
				<span class="cov7">*</span>
				<span class="cov8">*</span>
				<span class="cov9">*</span>
				<span class="cov10">high coverage</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package main

import (
        "context"
        "log"

        "github.com/dnsoftware/mpm-save-get-shares/config"
        "github.com/dnsoftware/mpm-save-get-shares/internal/app"
        "github.com/dnsoftware/mpm-save-get-shares/internal/constants"
        "github.com/dnsoftware/mpm-save-get-shares/pkg/utils"
)

func main() <span class="cov0" title="0">{
        ctx := context.Background()

        basePath, err := utils.GetProjectRoot(constants.ProjectRootAnchorFile)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("GetProjectRoot failed: %s", err.Error())
        }</span>
        <span class="cov0" title="0">configFile := basePath + "/config.yaml"
        envFile := basePath + "/.env"

        cfg, err := config.New(configFile, envFile)
        if err != nil </span>{<span class="cov0" title="0">

        }</span>

        <span class="cov0" title="0">err = app.Run(ctx, cfg)</span>

}
</pre>
		
		<pre class="file" id="file1" style="display: none">package config

import (
        "flag"
        "fmt"
        "log"
        "os"
        "strings"

        "github.com/joho/godotenv"
        "github.com/kelseyhightower/envconfig"
        "gopkg.in/yaml.v2"
)

type App struct {
        Name    string `yaml:"app_name" envconfig:"APP_NAME"    required:"true"`
        Version string `yaml:"app_version" envconfig:"APP_VERSION" required:"true"`
}

type KafkaShareReaderConfig struct {
        Brokers            []string `yaml:"brokers" envconfig:"KAFKA_SHARE_READER_BROKERS" required:"true"`
        Group              string   `yaml:"group" envconfig:"KAFKA_SHARE_READER_GROUP" required:"true"`
        Topic              string   `yaml:"topic" envconfig:"KAFKA_SHARE_READER_TOPIC" required:"true"`
        AutoCommitEnable   bool     `yaml:"auto_commit_enable" envconfig:"KAFKA_SHARE_AUTO_COMMIT_ENABLE" required:"true"`
        AutoCommitInterval int      `yaml:"auto_commit_interval" envconfig:"KAFKA_SHARE_AUTO_COMMIT_INTERVAL" required:"true"` // в секундах
}

type KafkaMetricWriterConfig struct {
        Brokers []string `yaml:"brokers" envconfig:"KAFKA_METRIC_WRITER_BROKERS" required:"true"`
        Topic   string   `yaml:"topic" envconfig:"KAFKA_METRIC_WRITER_TOPIC" required:"true"`
}

type GRPCConfig struct {
        CoinTarget  string `yaml:"coin_target" envconfig:"GRPC_COIN_TARGET" required:"true"`   // хост:порт удаленного хранилища Coin
        MinerTarget string `yaml:"miner_target" envconfig:"GRPC_MINER_TARGET" required:"true"` // хост:порт удаленного хранилища майнер/воркер
}

type Config struct {
        App               App                     `yaml:"application"`
        KafkaShareReader  KafkaShareReaderConfig  `yaml:"kafka_share_reader"`
        KafkaMetricWriter KafkaMetricWriterConfig `yaml:"kafka_metric_writer"`
        GRPC              GRPCConfig              `yaml:"grpc"`
}

func New(filePath string, envFile string) (Config, error) <span class="cov8" title="1">{
        var config Config
        var err error

        // 1. Читаем из config.yaml. Самый низкий приоритет
        file, err := os.Open(filePath)
        if err == nil </span><span class="cov8" title="1">{
                defer file.Close()
                decoder := yaml.NewDecoder(file)
                if decodeErr := decoder.Decode(&amp;config); decodeErr != nil </span><span class="cov0" title="0">{
                        log.Fatalf("Ошибка при чтении config.yaml: %v", decodeErr)
                }</span>
        } else<span class="cov0" title="0"> {
                log.Printf("config.yaml не найден, используются значения по умолчанию: %v", err)
        }</span>

        // 2.1 Загрузка переменных окружения из .env
        <span class="cov8" title="1">err = godotenv.Load(envFile)
        if err != nil </span><span class="cov0" title="0">{
                return config, fmt.Errorf("godotenv.Load: %w", err)
        }</span>

        // 2.2 Переопределяем переменные, полученные из конфиг файла
        <span class="cov8" title="1">err = envconfig.Process("", &amp;config)
        if err != nil </span><span class="cov0" title="0">{
                return config, fmt.Errorf("envconfig.Process: %w", err)
        }</span>

        // 3. Чтение параметров командной строки
        // Регистрируем флаги
        <span class="cov8" title="1">kafkaShareBrokers := flag.String("kafka_share_brokers", "", "Хост для подключения")

        // Устанавливаем тестовые аргументы
        flag.CommandLine.Parse([]string{"-kafka_share_brokers=localhost:9092"})

        flag.Parse()

        // для каждого аргумента проверяем не пустой ли он, и если не пустой - переопределяем переменную конфига
        if *kafkaShareBrokers != "" </span><span class="cov8" title="1">{
                config.KafkaShareReader.Brokers = strings.Split(*kafkaShareBrokers, ",")
        }</span>

        <span class="cov8" title="1">return config, nil</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package clickhouse

import "github.com/dnsoftware/mpm-save-get-shares/internal/entity"

type ClickHouseShareStorage struct {
}

func NewClickHouseShareStorage() (*ClickHouseShareStorage, error) <span class="cov8" title="1">{

        ss := &amp;ClickHouseShareStorage{}

        return ss, nil
}</span>

// CreateShare добавление шары в ClickHouse базу данных
// если возвращает nil - вставка прошла успешно
func (c *ClickHouseShareStorage) CreateShare(share entity.Share) error <span class="cov0" title="0">{
        return nil
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">package grpc

import (
        "context"
        "log"

        "google.golang.org/grpc"

        "github.com/dnsoftware/mpm-save-get-shares/internal/adapter/grpc/proto"
)

type GRPCCoinStorage struct {
        conn   *grpc.ClientConn
        client proto.MinersServiceClient
}

func NewCoinStorage(conn *grpc.ClientConn) (*GRPCCoinStorage, error) <span class="cov8" title="1">{

        client := proto.NewMinersServiceClient(conn)

        return &amp;GRPCCoinStorage{
                client: client,
                conn:   conn,
        }, nil
}</span>

func (g *GRPCCoinStorage) GetCoinIDByName(ctx context.Context, coin string) (int64, error) <span class="cov8" title="1">{

        state := g.conn.GetState()
        log.Printf("Connection state: %v", state.String())

        resp, err := g.client.GetCoinIDByName(ctx, &amp;proto.GetCoinIDByNameRequest{
                Coin: coin,
        })

        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov8" title="1">return resp.Id, err</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">// Package shares реализует обработчик шар, полученных из топика кафки
package shares

import (
        "context"

        "github.com/IBM/sarama"
        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/propagation"

        "github.com/dnsoftware/mpm-save-get-shares/internal/usecase/share"
)

// ShareConsumer реализует интерфейс sarama.ConsumerGroupHandler
type ShareConsumer struct {
        MsgChan chan *sarama.ConsumerMessage
        share.ShareUseCase
}

func NewShareConsumer(msgChan chan *sarama.ConsumerMessage, shareUseCase share.ShareUseCase) (*ShareConsumer, error) <span class="cov0" title="0">{
        return &amp;ShareConsumer{
                MsgChan:      msgChan,
                ShareUseCase: shareUseCase,
        }, nil
}</span>

// Setup вызывается перед началом обработки
func (consumer *ShareConsumer) Setup(session sarama.ConsumerGroupSession) error <span class="cov1" title="1">{

        return nil
}</span>

// Cleanup вызывается после завершения обработки
func (consumer *ShareConsumer) Cleanup(session sarama.ConsumerGroupSession) error <span class="cov1" title="1">{
        return nil
}</span>

// ConsumeClaim обрабатывает сообщения из партиций
// если используем канал consumer.MsgChan (или какой-то подобный) - нужно его вычитывать снаружи
func (consumer *ShareConsumer) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error <span class="cov1" title="1">{
        for msg := range claim.Messages() </span><span class="cov10" title="27">{
                // Создаем carrier для извлечения заголовков
                carrier := propagation.MapCarrier{}
                // Извлекаем контекст трассировки из заголовков
                // Преобразуем заголовки Kafka в формат map
                for _, header := range msg.Headers </span><span class="cov10" title="27">{
                        carrier[string(header.Key)] = string(header.Value)
                }</span>
                <span class="cov10" title="27">ctx := otel.GetTextMapPropagator().Extract(context.Background(), carrier)

                tracer := otel.Tracer("consume-share")
                ctx, span := tracer.Start(ctx, "process")

                consumer.MsgChan &lt;- msg
                // Тут идет вызов usecase

                // Если сообщение успешно обработано - помечаем, как обработанное TODO
                session.MarkMessage(msg, "")
                // иначе - логируем ошибку и делаем пометку "алерт" TODO
                // ...

                span.End()</span>
        }
        <span class="cov1" title="1">return nil</span>
}

// NormalizeShare Обработчик шары
// Получение кодов майнеров/воркеров из кеша или из Postgres
func (consumer *ShareConsumer) NormalizeShare(shareData []byte) {<span class="cov0" title="0">

}</span>
</pre>
		
		<pre class="file" id="file5" style="display: none">package postgres

import (
        "context"

        "github.com/jackc/pgx/v4/pgxpool"
)

type PostgresCoinStorage struct {
        pool *pgxpool.Pool
}

func NewPostgresCoinStorage(pool *pgxpool.Pool) (*PostgresCoinStorage, error) <span class="cov10" title="2">{

        storage := &amp;PostgresCoinStorage{
                pool: pool,
        }

        return storage, nil
}</span>

func (c *PostgresCoinStorage) GetCoinIDByName(ctx context.Context, coin string) (int64, error) <span class="cov10" title="2">{
        var id int64
        err := c.pool.QueryRow(ctx, `SELECT id FROM coins WHERE symbol = $1`,
                coin).Scan(&amp;id)

        return id, err

}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">package postgres

import (
        "context"
        "time"

        "github.com/jackc/pgx/v4"
        "github.com/jackc/pgx/v4/pgxpool"

        "github.com/dnsoftware/mpm-save-get-shares/internal/entity"
)

type PostgresMinerStorage struct {
        pool *pgxpool.Pool
        //db   *sql.DB
}

func NewPostgresMinerStorage(pool *pgxpool.Pool) (*PostgresMinerStorage, error) <span class="cov8" title="3">{

        storage := &amp;PostgresMinerStorage{
                pool: pool,
        }

        return storage, nil
}</span>

func (p *PostgresMinerStorage) CreateWallet(ctx context.Context, wallet entity.Wallet) (int64, error) <span class="cov10" title="4">{
        var newID int64
        err := p.pool.QueryRow(ctx, `INSERT INTO wallets (coin_id, name, is_solo, reward_method) 
                        VALUES ($1, $2, $3, $4) RETURNING id`,
                wallet.CoinID, wallet.Name, wallet.IsSolo, wallet.RewardMethod).Scan(&amp;newID)

        return newID, err
}</span>

func (p *PostgresMinerStorage) CreateWorker(ctx context.Context, worker entity.Worker) (int64, error) <span class="cov10" title="4">{
        created_at := time.Now().Format("2006-01-02 15:04:05.000")
        updated_at := time.Now().Format("2006-01-02 15:04:05.000")

        var newID int64
        err := p.pool.QueryRow(ctx, `INSERT INTO workers (coin_id, workerfull, wallet, worker, server_id, created_at, updated_at, reward_method) 
                        VALUES ($1, $2, $3, $4, $5, $6, $7, $8) RETURNING id`,
                worker.CoinID, worker.Workerfull, worker.Wallet, worker.Worker, worker.ServerID, created_at, updated_at, worker.RewardMethod).Scan(&amp;newID)

        return newID, err
}</span>

func (p *PostgresMinerStorage) GetWalletIDByName(ctx context.Context, wallet string, coinID int64, rewardMethod string) (int64, error) <span class="cov10" title="4">{
        var id int64
        err := p.pool.QueryRow(ctx, `SELECT id FROM wallets WHERE name = $1 AND coin_id = $2 AND reward_method = $3`,
                wallet, coinID, rewardMethod).Scan(&amp;id)

        if err != nil </span><span class="cov8" title="3">{
                if err == pgx.ErrNoRows </span><span class="cov8" title="3">{
                        // Если нет записей
                        return 0, nil
                }</span> else<span class="cov0" title="0"> {
                        // Обработка других ошибок
                        return 0, err
                }</span>
        }

        <span class="cov1" title="1">return id, err</span>
}

func (p *PostgresMinerStorage) GetWorkerIDByName(ctx context.Context, workerFull string, coinID int64, rewardMethod string) (int64, error) <span class="cov10" title="4">{

        var id int64
        err := p.pool.QueryRow(ctx, `SELECT id FROM workers WHERE workerfull = $1 AND coin_id = $2 AND reward_method = $3`,
                workerFull, coinID, rewardMethod).Scan(&amp;id)

        if err != nil </span><span class="cov8" title="3">{
                if err == pgx.ErrNoRows </span><span class="cov8" title="3">{
                        // Если нет записей
                        return 0, nil
                }</span> else<span class="cov0" title="0"> {
                        // Обработка других ошибок
                        return 0, err
                }</span>
        }

        <span class="cov1" title="1">return id, err</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">package ristretto

import (
        "fmt"

        "github.com/dgraph-io/ristretto"
)

type RistrettoCoinStorage struct {
        cache *ristretto.Cache
}

func NewRistrettoCoinStorage() (*RistrettoCoinStorage, error) <span class="cov0" title="0">{
        cache, err := ristretto.NewCache(&amp;ristretto.Config{
                NumCounters: 1e4,     // Количество счётчиков для элементов
                MaxCost:     1 &lt;&lt; 24, // Максимальная стоимость (в байтах)
                BufferItems: 64,      // Количество буферных элементов
        })

        return &amp;RistrettoCoinStorage{
                cache: cache,
        }, err
}</span>

func (c *RistrettoCoinStorage) CreateCoin(key string, value int64) (int64, error) <span class="cov0" title="0">{
        c.cache.Set(key, value, 1)
        c.cache.Wait()

        val, isFound := c.cache.Get(key)
        if !isFound </span><span class="cov0" title="0">{
                return 0, nil
        }</span>

        <span class="cov0" title="0">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoCoinStorage CreateCoin error: значение не того типа")
        }</span>

        <span class="cov0" title="0">return newID, nil</span>
}

func (c *RistrettoCoinStorage) GetCoinIDByName(coin string) (int64, error) <span class="cov0" title="0">{

        val, isFound := c.cache.Get(coin)
        if !isFound </span><span class="cov0" title="0">{
                return 0, nil
        }</span>

        <span class="cov0" title="0">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoCoinStorage GetCoinIDByName error: значение не того типа")
        }</span>

        <span class="cov0" title="0">return newID, nil</span>

}
</pre>
		
		<pre class="file" id="file8" style="display: none">package ristretto

import (
        "fmt"

        "github.com/dgraph-io/ristretto"

        "github.com/dnsoftware/mpm-save-get-shares/internal/entity"
)

type RistrettoMinerStorage struct {
        cache *ristretto.Cache
}

func NewRistrettoMinerStorage() (*RistrettoMinerStorage, error) <span class="cov1" title="1">{
        cache, err := ristretto.NewCache(&amp;ristretto.Config{
                NumCounters: 1e7,     // Количество счётчиков для элементов
                MaxCost:     1 &lt;&lt; 30, // Максимальная стоимость (в байтах)
                BufferItems: 64,      // Количество буферных элементов
                //Cost: func(value interface{}) int64 {
                //        if str, ok := value.(string); ok {
                //                return int64(len(str)) // Стоимость — длина строки
                //        }
                //        return 1
                //},
        })

        return &amp;RistrettoMinerStorage{
                cache: cache,
        }, err
}</span>

func (p *RistrettoMinerStorage) makeKey(obj interface{}) (string, error) <span class="cov10" title="2">{

        var key string

        switch v := obj.(type) </span>{
        case entity.Wallet:<span class="cov1" title="1">
                coinIDStr := fmt.Sprintf("%v", v.CoinID)
                key = v.Name + coinIDStr + v.RewardMethod
                return key, nil</span>
        case entity.Worker:<span class="cov1" title="1">
                coinIDStr := fmt.Sprintf("%v", v.CoinID)
                key = v.Workerfull + coinIDStr + v.RewardMethod
                return key, nil</span>
        default:<span class="cov0" title="0"> // нет совпадения, v имеет тип значения интерфейса x
                return "", fmt.Errorf("bad cached object")</span>
        }

}

// CreateWallet закэшировать ID кошелька (майнера)
// wallet - должен уже иметь ID
func (p *RistrettoMinerStorage) CreateWallet(wallet entity.Wallet) (int64, error) <span class="cov1" title="1">{
        key, err := p.makeKey(wallet)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov1" title="1">p.cache.Set(key, wallet.ID, 1)
        p.cache.Wait()

        val, isFound := p.cache.Get(key)
        if !isFound </span><span class="cov0" title="0">{
                return 0, nil
        }</span>

        <span class="cov1" title="1">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoMinerStorage CreateWallet error: значение не того типа")
        }</span>

        <span class="cov1" title="1">return newID, nil</span>
}

// CreateWorker закэшировать ID воркера
// worker - должен уже иметь ID
func (p *RistrettoMinerStorage) CreateWorker(worker entity.Worker) (int64, error) <span class="cov1" title="1">{
        key, err := p.makeKey(worker)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov1" title="1">p.cache.Set(key, worker.ID, 1)
        p.cache.Wait()

        val, isFound := p.cache.Get(key)
        if !isFound </span><span class="cov0" title="0">{
                return 0, nil
        }</span>

        <span class="cov1" title="1">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoMinerStorage CreateWorker error: значение не того типа")
        }</span>

        <span class="cov1" title="1">return newID, nil</span>
}

func (p *RistrettoMinerStorage) GetWalletIDByName(walletName string, coinID int64, rewardMethod string) (int64, error) <span class="cov10" title="2">{
        coinIDStr := fmt.Sprintf("%v", coinID)
        key := walletName + coinIDStr + rewardMethod
        val, isFound := p.cache.Get(key)
        if !isFound </span><span class="cov1" title="1">{
                return 0, nil
        }</span>

        <span class="cov1" title="1">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoMinerStorage GetWalletIDByName error: значение не того типа")
        }</span>

        <span class="cov1" title="1">return newID, nil</span>
}

func (p *RistrettoMinerStorage) GetWorkerIDByName(workerName string, coinID int64, rewardMethod string) (int64, error) <span class="cov10" title="2">{
        coinIDStr := fmt.Sprintf("%v", coinID)
        key := workerName + coinIDStr + rewardMethod
        val, isFound := p.cache.Get(key)
        if !isFound </span><span class="cov1" title="1">{
                return 0, nil
        }</span>

        <span class="cov1" title="1">newID, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("RistrettoMinerStorage GetWorkerIDByName error: значение не того типа")
        }</span>

        <span class="cov1" title="1">return newID, nil</span>
}
</pre>
		
		<pre class="file" id="file9" style="display: none">package app

import (
        "context"

        "github.com/dnsoftware/mpm-save-get-shares/config"
)

type Dependencies struct {
}

func Run(ctx context.Context, cfg config.Config) (err error) <span class="cov0" title="0">{
        var deps Dependencies
        _ = deps

        /********* Инициализация трассировщика **********/
        /********* КОНЕЦ Инициализация трассировщика **********/

        return nil
}</span>
</pre>
		
		<pre class="file" id="file10" style="display: none">package dto

import (
        "time"

        "github.com/dnsoftware/mpm-save-get-shares/internal/entity"
)

// ShareFound Структура данных шары получаемой из Кафки
type ShareFound struct {
        Uuid         string `json:"uuid"`         // уникальный идентификатор
        BlockType    string `json:"blockType"`    //
        ServerID     string `json:"serverId"`     // идентификатор пул-сервера (типа ALEPH-1 и т.п.)
        CoinSymbol   string `json:"coinSymbol"`   // идентификатор монеты
        Workerfull   string `json:"workerfull"`   // полный идентификатор воркера
        ShareDate    int64  `json:"shareDate"`    // время когда найдено, в миллисекундах
        CHrate       int64  `json:"cHrate"`       // текущий хешрейт
        AHrate       int64  `json:"aHrate"`       // средний хешрейт
        Difficulty   string `json:"difficulty"`   // сложность майнера
        Sharedif     string `json:"sharedif"`     // сложность шары        реальная
        Nonce        string `json:"nonce"`        // nonce шары
        MinerIp      string `json:"minerIp"`      // IP майнера, приславшего шару
        IsSolo       bool   `json:"isSolo"`       // соло режим
        RewardMethod string `json:"rewardMethod"` // метод начисления вознаграждения
        Cost         string `json:"cost"`         // награда за шару
}

// ToShare Частичный маппинг в entity.Share
// CoinID, WorkerID, WalletID - заполняются потом
func (s *ShareFound) ToShare() entity.Share <span class="cov10" title="27">{

        // Создаем объект времени из миллисекунд
        t := time.UnixMilli(s.ShareDate)

        share := entity.Share{
                UUID:         s.Uuid,
                ServerID:     s.ServerID,
                CoinID:       0, // заполняется в usecase
                WorkerID:     0, // заполняется в usecase
                WalletID:     0, // заполняется в usecase
                ShareDate:    t.Format("2006-01-02 15:04:05.999"),
                Difficulty:   s.Difficulty,
                Sharedif:     s.Sharedif,
                Nonce:        s.Nonce,
                IsSolo:       s.IsSolo,
                RewardMethod: s.RewardMethod,
                Cost:         s.Cost,
        }

        return share
}</span>
</pre>
		
		<pre class="file" id="file11" style="display: none">package share

import (
        "strings"

        "github.com/dnsoftware/mpm-save-get-shares/internal/constants"
)

// WalletFromWorkerfull получить кошелек из полного имени воркера
func WalletFromWorkerfull(workerfull string) string <span class="cov10" title="27">{
        parts := strings.Split(workerfull, constants.WorkerSeparator)

        return parts[0]
}</span>

// WorkerFromWorkerfull получить короткое имя воркера из полного имени воркера
func WorkerFromWorkerfull(workerfull string) string <span class="cov10" title="27">{
        parts := strings.Split(workerfull, constants.WorkerSeparator)

        if len(parts) &gt; 1 </span><span class="cov10" title="27">{
                return parts[1]
        }</span> else<span class="cov0" title="0"> {
                return ""
        }</span>

}
</pre>
		
		<pre class="file" id="file12" style="display: none">package share

import (
        "context"
        "fmt"
        "time"

        "github.com/dnsoftware/mpm-save-get-shares/internal/dto"
        "github.com/dnsoftware/mpm-save-get-shares/internal/entity"
)

// NormalizeShare нормализация шары
// получаем коды монеты. майнера, воркера из кеша или из базы, чтобы сформировать структуру шары для вставки в базу данных
func (u *ShareUseCase) NormalizeShare(shareFound dto.ShareFound) (entity.Share, error) <span class="cov10" title="27">{
        ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
        defer cancel()

        //*** получение кода монеты в базе
        coinID, err := u.coinCache.GetCoinIDByName(shareFound.CoinSymbol)
        if err != nil </span><span class="cov0" title="0">{
                return entity.Share{}, err
        }</span>
        <span class="cov10" title="27">if coinID == 0 </span><span class="cov1" title="1">{ // в кэше нет
                coinID, err = u.coinStorage.GetCoinIDByName(ctx, shareFound.CoinSymbol)
                if err != nil </span><span class="cov0" title="0">{
                        return entity.Share{}, err
                }</span>
                <span class="cov1" title="1">if coinID == 0 </span><span class="cov0" title="0">{ // в базе нет (а должна быть, так как в миграциях заполнили все монеты в таблице)
                        return entity.Share{}, fmt.Errorf("coinID must be greater then 0")
                }</span>

                <span class="cov1" title="1">coinID, err = u.coinCache.CreateCoin(shareFound.CoinSymbol, coinID) // кешируем
                if err != nil </span><span class="cov0" title="0">{
                        return entity.Share{}, err
                }</span>
                <span class="cov1" title="1">if coinID == 0 </span><span class="cov0" title="0">{ // в кеше должна быть уже
                        return entity.Share{}, fmt.Errorf("coinID in cache must be greater then 0")
                }</span>

        }

        //*** получение кода майнера(кошелька) в базе
        <span class="cov10" title="27">walletName := WalletFromWorkerfull(shareFound.Workerfull)

        // Запрашиваем данные майнера из кеша
        walletID, err := u.minerCache.GetWalletIDByName(walletName, coinID, shareFound.RewardMethod)
        if err != nil </span><span class="cov0" title="0">{
                return entity.Share{}, err
        }</span>
        <span class="cov10" title="27">if walletID == 0 </span><span class="cov4" title="3">{ // нет в кеше
                walletID, err = u.minerStorage.GetWalletIDByName(ctx, walletName, coinID, shareFound.RewardMethod)
                if err != nil </span><span class="cov0" title="0">{
                        return entity.Share{}, err
                }</span>
                <span class="cov4" title="3">if walletID == 0 </span><span class="cov4" title="3">{ // нет в базе
                        walletEntity := entity.Wallet{
                                ID:           0,
                                CoinID:       coinID,
                                Name:         walletName,
                                IsSolo:       shareFound.IsSolo,
                                RewardMethod: shareFound.RewardMethod,
                        }

                        walletID, err = u.minerStorage.CreateWallet(ctx, walletEntity)
                        if err != nil </span><span class="cov0" title="0">{
                                return entity.Share{}, err
                        }</span>
                        <span class="cov4" title="3">walletEntity.ID = walletID

                        walletID, err = u.minerCache.CreateWallet(walletEntity)
                        walletEntity.ID = walletID</span>
                }
        }

        //*** получение кода воркера в базе
        <span class="cov10" title="27">workerName := WorkerFromWorkerfull(shareFound.Workerfull)

        // Запрашиваем данные воркера из кеша
        workerID, err := u.minerCache.GetWorkerIDByName(shareFound.Workerfull, coinID, shareFound.RewardMethod)
        if err != nil </span><span class="cov0" title="0">{
                return entity.Share{}, err
        }</span>
        <span class="cov10" title="27">if workerID == 0 </span><span class="cov4" title="3">{ // нет в кеше
                workerID, err = u.minerStorage.GetWorkerIDByName(ctx, shareFound.Workerfull, coinID, shareFound.RewardMethod)
                if err != nil </span><span class="cov0" title="0">{
                        return entity.Share{}, err
                }</span>
                <span class="cov4" title="3">if workerID == 0 </span><span class="cov4" title="3">{ // нет в базе
                        workerEntity := entity.Worker{
                                ID:           0,
                                CoinID:       coinID,
                                Workerfull:   shareFound.Workerfull,
                                Wallet:       walletName,
                                Worker:       workerName,
                                ServerID:     shareFound.ServerID,
                                IP:           shareFound.MinerIp,
                                IsSolo:       shareFound.IsSolo,
                                RewardMethod: shareFound.RewardMethod,
                        }

                        workerID, err = u.minerStorage.CreateWorker(ctx, workerEntity)
                        if err != nil </span><span class="cov0" title="0">{
                                return entity.Share{}, err
                        }</span>
                        <span class="cov4" title="3">workerEntity.ID = workerID

                        workerID, err = u.minerCache.CreateWorker(workerEntity)
                        workerEntity.ID = workerID</span>
                }
        }

        // формируем entity.Share
        <span class="cov10" title="27">share := shareFound.ToShare()
        share.CoinID = coinID
        share.WalletID = walletID
        share.WorkerID = workerID

        return share, nil</span>
}
</pre>
		
		<pre class="file" id="file13" style="display: none">package share

import (
        "github.com/dnsoftware/mpm-save-get-shares/internal/dto"
)

// SaveShare сохранение шары в базе данных (ClickHouse)
// Возвращает nil, если запись была добавлена успешно
func (u *ShareUseCase) SaveShare(shareFound dto.ShareFound) error <span class="cov0" title="0">{

        return nil
}</span>
</pre>
		
		<pre class="file" id="file14" style="display: none">package share

import (
        "context"

        "github.com/dnsoftware/mpm-save-get-shares/internal/entity"
)

// SharesStorage сохранение шары в хранилище (ClickHouse)
type ShareStorage interface {
        CreateShare(share entity.Share) error // если возвращает nil - вставка прошла учпешно
}

// MinerStorage сохранение/получение данных майнеров (кошельков) и воркеров в справочники в хранилище (Postgresql или кэш (ristretto))
type MinerStorage interface {
        CreateWallet(ctx context.Context, wallet entity.Wallet) (int64, error)
        CreateWorker(ctx context.Context, worker entity.Worker) (int64, error)
        GetWalletIDByName(ctx context.Context, wallet string, coinID int64, rewardMethod string) (int64, error) // 0 - если не найден
        GetWorkerIDByName(ctx context.Context, worker string, coinID int64, rewardMethod string) (int64, error) // 0 - если не найден
}

// CoinStorage работа с данными о монете из хранилища  (Postgresql или кэш (ristretto))
// Метода сохранения в базу нет, потому что подразумевается что база уже заполнена
type CoinStorage interface {
        // GetCoinIDByName получение кода монеты в базе по буквенному коду (ALPH, KAS и т.д.), если не найдено - возвращаем ошибку
        GetCoinIDByName(ctx context.Context, coin string) (int64, error)
}

// MinerCache работа с кэшированными данными майнеров
type MinerCache interface {
        CreateWallet(wallet entity.Wallet) (int64, error)
        CreateWorker(worker entity.Worker) (int64, error)
        GetWalletIDByName(wallet string, coinID int64, rewardMethod string) (int64, error) // 0 - если не найден
        GetWorkerIDByName(worker string, coinID int64, rewardMethod string) (int64, error) // 0 - если не найден
}

// CoinCache работа с кэшированными данными о монете
type CoinCache interface {
        CreateCoin(key string, value int64) (int64, error) // занесение кода монеты в кэш
        GetCoinIDByName(coin string) (int64, error)        // получение кода монеты из кэша по буквенному коду (ALPH, KAS и т.д.)
}

type ShareUseCase struct {
        shareStorage ShareStorage // персистентная база (ClickHouse)
        minerStorage MinerStorage // персистентная база (Postgresql)
        coinStorage  CoinStorage  // персистентная база (Postgresql)
        minerCache   MinerCache   // кэш в оперативной памяти для майнеров
        coinCache    CoinCache    // кэш в оперативной памяти для монет
}

func NewShareUseCase(s ShareStorage, m MinerStorage, c CoinStorage, mc MinerCache, cc CoinCache) *ShareUseCase <span class="cov8" title="1">{
        return &amp;ShareUseCase{
                shareStorage: s,
                minerStorage: m,
                coinStorage:  c,
                minerCache:   mc,
                coinCache:    cc,
        }
}</span>
</pre>
		
		<pre class="file" id="file15" style="display: none">package kafka_reader

import (
        "context"
        "fmt"
        "log"
        "sync"
        "time"

        "github.com/IBM/sarama"

        "github.com/dnsoftware/mpm-save-get-shares/pkg/logger"
)

type Config struct {
        Brokers            []string
        Group              string
        Topic              string
        AutoCommitEnable   bool
        AutoCommitInterval int
}

type KafkaReader struct {
        brokers       []string
        group         string
        topic         string
        consumerGroup sarama.ConsumerGroup
        ctx           context.Context
        cancel        context.CancelFunc
        wg            sync.WaitGroup
        logger        logger.MPMLogger
        admin         sarama.ClusterAdmin
}

func NewKafkaReader(cfg Config, logger logger.MPMLogger) (*KafkaReader, error) <span class="cov0" title="0">{
        // Настройка конфигурации
        config := sarama.NewConfig()
        config.Consumer.Offsets.Initial = sarama.OffsetOldest                                             // Чтение с самого начала (если нет сохраненного оффсета)
        config.Consumer.Offsets.AutoCommit.Enable = cfg.AutoCommitEnable                                  // Включаем автоматическое сохранение оффсетов
        config.Consumer.Offsets.AutoCommit.Interval = time.Duration(cfg.AutoCommitInterval) * time.Second // Интервал для сохранения оффсетов - 10 секунд

        // Создаем клиента для consumer группы
        consumerGroup, err := sarama.NewConsumerGroup(cfg.Brokers, cfg.Group, config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">admin, err := sarama.NewClusterAdmin(cfg.Brokers, config)
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Ошибка при создании ClusterAdmin: %v", err)
        }</span>

        // Создание контекста для управления остановкой
        <span class="cov0" title="0">ctx, cancel := context.WithCancel(context.Background())

        return &amp;KafkaReader{
                brokers:       cfg.Brokers,
                group:         cfg.Group,
                topic:         cfg.Topic,
                consumerGroup: consumerGroup,
                ctx:           ctx,
                cancel:        cancel,
                logger:        logger,
                admin:         admin,
        }, nil</span>
}

// ConsumeMessages - запуск чтения сообщений из топика
func (r *KafkaReader) ConsumeMessages(handler sarama.ConsumerGroupHandler) <span class="cov0" title="0">{
        r.wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer r.wg.Done()

                // Бесконечный цикл чтения сообщений
                for </span><span class="cov0" title="0">{
                        // Если контекст завершён, выходим из цикла
                        if r.ctx.Err() != nil </span><span class="cov0" title="0">{
                                return
                        }</span>

                        <span class="cov0" title="0">if err := r.consumerGroup.Consume(r.ctx, []string{r.topic}, handler); err != nil </span><span class="cov0" title="0">{
                                r.logger.Error(fmt.Sprintf("Ошибка при чтении сообщений, Group: %s, Topic: %s: %v", r.group, r.topic, err))
                        }</span>

                }
        }()

        <span class="cov0" title="0">return</span>
}

func (r *KafkaReader) Close() <span class="cov0" title="0">{
        // Отмена контекста
        r.cancel()
        // Ожидание завершения горутин
        r.wg.Wait()
        // Закрытие Consumer Group
        if err := r.consumerGroup.Close(); err != nil </span><span class="cov0" title="0">{
                r.logger.Error(fmt.Sprintf("Ошибка закрытия Consumer Group, Group: %s, Topic: %s: %v", r.group, r.topic, err))
        }</span>

        <span class="cov0" title="0">if err := r.admin.Close(); err != nil </span><span class="cov0" title="0">{
                r.logger.Error(fmt.Sprintf("Ошибка закрытия ClusterAdmin: %v", err))
        }</span>

        <span class="cov0" title="0">r.logger.Info(fmt.Sprintf("KafkaConsumer завершён, Group: %s, Topic: %s", r.group, r.topic))</span>
}

// SetGroupOffset Сбрасывает для текущей группы смещение топика в начало
func (r *KafkaReader) SetGroupOffset(offset int64) error <span class="cov0" title="0">{
        // Создание нового клиента
        client, err := sarama.NewClient(r.brokers, nil)
        if err != nil </span><span class="cov0" title="0">{
                r.logger.Error(fmt.Sprintf("Failed to create Kafka client: %s", err))
                return err
        }</span>
        <span class="cov0" title="0">defer client.Close()

        // Создание OffsetManager
        offsetManager, err := sarama.NewOffsetManagerFromClient(r.group, client)
        if err != nil </span><span class="cov0" title="0">{
                r.logger.Error(fmt.Sprintf("Failed to create offset manager: %s", err))
                return err
        }</span>
        <span class="cov0" title="0">defer offsetManager.Close()

        // Получение информации о партициях топика
        partitions, err := client.Partitions(r.topic)
        if err != nil </span><span class="cov0" title="0">{
                r.logger.Error(fmt.Sprintf("Failed to get partitions: %s", err))
        }</span>

        // Установка конкретных смещений по партициям
        <span class="cov0" title="0">for _, partition := range partitions </span><span class="cov0" title="0">{
                partitionManager, err := offsetManager.ManagePartition(r.topic, partition)
                if err != nil </span><span class="cov0" title="0">{
                        r.logger.Error(fmt.Sprintf("Failed to manage partition %d: %v", partition, err))
                        continue</span>
                }
                <span class="cov0" title="0">defer partitionManager.Close()

                // Устанавливаем смещение на начало
                desiredOffset := offset

                // Устанавливаем смещение
                partitionManager.ResetOffset(desiredOffset, "")

                r.logger.Info(fmt.Sprintf("Set offset for partition %d to %d\n", partition, desiredOffset))</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">package kafka_writer

import "github.com/IBM/sarama"

type SaramaHeadersCarrier []sarama.RecordHeader

/**** Реализация интерфейса TextMapCarrier ****/
/**/
func (c *SaramaHeadersCarrier) Get(key string) string <span class="cov0" title="0">{
        for _, h := range *c </span><span class="cov0" title="0">{
                if string(h.Key) == key </span><span class="cov0" title="0">{
                        return string(h.Value)
                }</span>
        }
        <span class="cov0" title="0">return ""</span>
}

func (c *SaramaHeadersCarrier) Set(key, value string) <span class="cov8" title="1">{
        *c = append(*c, sarama.RecordHeader{Key: []byte(key), Value: []byte(value)})
}</span>

func (c *SaramaHeadersCarrier) Keys() []string <span class="cov0" title="0">{
        keys := make([]string, len(*c))
        for i, h := range *c </span><span class="cov0" title="0">{
                keys[i] = string(h.Key)
        }</span>
        <span class="cov0" title="0">return keys</span>
}

/**/
</pre>
		
		<pre class="file" id="file17" style="display: none">package kafka_writer

import (
        "context"
        "fmt"
        "log"
        "os"
        "os/signal"
        "sync"
        "syscall"
        "time"

        "github.com/IBM/sarama"
        "go.opentelemetry.io/otel"

        "github.com/dnsoftware/mpm-save-get-shares/pkg/logger"
)

type Config struct {
        Brokers []string
        Topic   string
}

// KafkaWriter - структура для асинхронного продюсера
type KafkaWriter struct {
        brokers  []string
        topic    string
        producer sarama.AsyncProducer
        stop     chan os.Signal
        wg       sync.WaitGroup
        logger   logger.MPMLogger
}

// NewKafkaWriter - конструктор для создания нового KafkaProducer
func NewKafkaWriter(cfg Config, logger logger.MPMLogger) (*KafkaWriter, error) <span class="cov8" title="1">{
        // Конфигурация продюсера
        config := sarama.NewConfig()
        config.Producer.RequiredAcks = sarama.WaitForLocal        // Дождаться подтверждения от лидера
        config.Producer.Retry.Max = 5                             // Количество попыток повторной отправки
        config.Producer.Return.Successes = true                   // Возвращать успешные отправки
        config.Producer.Return.Errors = true                      // Возвращать ошибки отправки
        config.Producer.Partitioner = sarama.NewRandomPartitioner // Случайное распределение по партициям
        config.Producer.Retry.Backoff = 200 * time.Millisecond    // Задержка между попытками

        // Настройка пакетной отправки
        config.Producer.Flush.Frequency = 500 * time.Millisecond // Отправлять каждые 500 мс
        config.Producer.Flush.Bytes = 1024 * 1024                // Отправлять при накоплении 1 МБ данных
        config.Producer.Flush.Messages = 100                     // Отправлять каждые 100 сообщений
        config.Producer.Flush.MaxMessages = 1000                 // Максимум 1000 сообщений в пакете

        // Ограничения по размеру сообщений
        config.Producer.MaxMessageBytes = 10 * 1024 * 1024 // Максимальный размер одного сообщения: 10 МБ

        // Создание асинхронного продюсера
        producer, err := sarama.NewAsyncProducer(cfg.Brokers, config)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return &amp;KafkaWriter{
                brokers:  cfg.Brokers,
                topic:    cfg.Topic,
                producer: producer,
                stop:     make(chan os.Signal, 1),
                logger:   logger,
        }, nil</span>
}

// Start - метод для запуска продюсера
func (k *KafkaWriter) Start() <span class="cov8" title="1">{
        // Обработка сигналов для завершения работы
        signal.Notify(k.stop, os.Interrupt, syscall.SIGTERM)

        // Горутина для обработки успешных сообщений
        k.wg.Add(1)
        go func() </span><span class="cov8" title="1">{
                defer k.wg.Done()
                for success := range k.producer.Successes() </span><span class="cov8" title="1">{
                        log.Printf("Сообщение успешно отправлено в партицию %d, с оффсетом %d", success.Partition, success.Offset)
                }</span>
        }()

        // Горутина для обработки ошибок
        <span class="cov8" title="1">k.wg.Add(1)
        go func() </span><span class="cov8" title="1">{
                defer k.wg.Done()
                for err := range k.producer.Errors() </span><span class="cov0" title="0">{
                        k.logger.Error(fmt.Sprintf("Ошибка отправки сообщения: %v", err.Err))
                }</span>
        }()
}

// SendMessage - метод для отправки сообщения в Kafka
func (k *KafkaWriter) SendMessage(ctx context.Context, key string, value string) <span class="cov8" title="1">{

        message := &amp;sarama.ProducerMessage{
                Topic: k.topic,
                Key:   sarama.StringEncoder(key), // Ключ сообщения
                Value: sarama.StringEncoder(value),
        }

        // Заголовки Kafka и инъекция контекста трассировки в них
        headers := SaramaHeadersCarrier(make([]sarama.RecordHeader, 0))
        propagator := otel.GetTextMapPropagator()
        propagator.Inject(ctx, &amp;headers) // Передаём указатель на адаптер
        message.Headers = headers

        // Отправка сообщения
        k.producer.Input() &lt;- message
}</span>

// Close - метод для закрытия продюсера
func (k *KafkaWriter) Close() <span class="cov8" title="1">{
        k.producer.AsyncClose() // завершение работы асинхронного продюсера и закрытие канало Errors() и Successes()
        k.wg.Wait()             // Ожидание завершения горутин обработки Errors() и Successes()

        k.logger.Info(fmt.Sprintf("Работа KafkaWriter завершена"))
}</span>

func (k *KafkaWriter) DeleteTopic(topic string) error <span class="cov8" title="1">{
        // Создаем конфигурацию Sarama
        config := sarama.NewConfig()
        //config.Version = sarama.V3_0_0_0 // Убедитесь, что используемая версия Kafka поддерживает удаление топиков

        // Создаем ClusterAdmin
        admin, err := sarama.NewClusterAdmin(k.brokers, config)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">defer admin.Close()

        // Удаляем топик
        err = admin.DeleteTopic(topic)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">return nil</span>
}
</pre>
		
		<pre class="file" id="file18" style="display: none">package logger

import (
        "os"
        "sync"

        "go.uber.org/zap"
        "go.uber.org/zap/zapcore"

        "github.com/dnsoftware/mpm-save-get-shares/internal/constants"
        "github.com/dnsoftware/mpm-save-get-shares/pkg/utils"
)

const LogLevelProduction = "production"
const LogLevelDebug = "debug"

type Logger struct {
        *zap.Logger
}

var (
        instance *Logger
        once     sync.Once
)

func getLogLevel(env string) zapcore.Level <span class="cov8" title="1">{
        if env == LogLevelProduction </span><span class="cov0" title="0">{
                return zapcore.InfoLevel
        }</span>
        <span class="cov8" title="1">return zapcore.DebugLevel</span>
}

func getFileWriter(filePath string) zapcore.WriteSyncer <span class="cov8" title="1">{
        file, err := os.OpenFile(filePath, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
        if err != nil </span><span class="cov0" title="0">{
                panic(err)</span>
        }
        <span class="cov8" title="1">return zapcore.AddSync(file)</span>
}

func InitLogger(env string, filePath string) <span class="cov8" title="1">{
        once.Do(func() </span><span class="cov8" title="1">{
                logLevel := getLogLevel(env)
                encoderConfig := zap.NewProductionEncoderConfig()

                if env == LogLevelProduction </span><span class="cov0" title="0">{
                        encoderConfig = zap.NewProductionEncoderConfig()
                        encoderConfig.EncodeLevel = zapcore.LowercaseLevelEncoder
                }</span>
                <span class="cov8" title="1">encoder := zapcore.NewJSONEncoder(encoderConfig)
                core := zapcore.NewTee(
                        zapcore.NewCore(encoder, getFileWriter(filePath), logLevel),
                )

                if env != LogLevelProduction </span><span class="cov8" title="1">{
                        // Добавить вывод в консоль в режиме отладки
                        encoderConfig.EncodeLevel = zapcore.CapitalColorLevelEncoder // добавим подсветку при выводе в консоль в режиме отладки
                        encoder = zapcore.NewConsoleEncoder(encoderConfig)
                        consoleCore := zapcore.NewCore(encoder, zapcore.AddSync(os.Stdout), logLevel)
                        core = zapcore.NewTee(core, consoleCore)
                }</span>

                <span class="cov8" title="1">logger := zap.New(core, zap.AddCaller(), zap.AddStacktrace(zapcore.ErrorLevel))
                instance = &amp;Logger{logger}</span>
        })
}

func Log() *Logger <span class="cov8" title="1">{
        if instance == nil </span><span class="cov0" title="0">{
                panic("Logger is not initialized. Call InitLogger() before using GetLogger()")</span>
        }
        <span class="cov8" title="1">return instance</span>
}

func GetLoggerMainLogPath() (string, error) <span class="cov0" title="0">{
        dir, err := utils.GetProjectRoot(constants.ProjectRootAnchorFile)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">filePath := dir + "/" + constants.AppLogFile

        return filePath, nil</span>
}

func GetLoggerTestLogPath() (string, error) <span class="cov0" title="0">{
        dir, err := utils.GetProjectRoot(constants.ProjectRootAnchorFile)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>
        <span class="cov0" title="0">filePath := dir + "/" + constants.TestLogFile

        return filePath, nil</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">package otel

import (
        "context"
        "log"
        "strings"
        "time"

        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
        "go.opentelemetry.io/otel/exporters/stdout/stdouttrace"
        "go.opentelemetry.io/otel/propagation"
        "go.opentelemetry.io/otel/sdk/resource"
        "go.opentelemetry.io/otel/sdk/trace"
        semconv "go.opentelemetry.io/otel/semconv/v1.21.0"
)

type Config struct {
        ServiceName        string        // Название сервиса (чтобы понимать с какого сервера идет трассировка и т.п.)
        CollectorEndpoint  string        // адрес:порт Otel коллектора, куда будут отсылаться трассировки
        BatchTimeout       time.Duration // через указанный период времени данные по трассировкам будут отправляться в одном пакете
        MaxExportBatchSize int           // Максимальное кол-во спанов в пакете
        MaxQueueSize       int           // Максимум спанов в очереди
}

// InitTracer Инициализация трассировщика, вызывать в самом начале программы
// Пример вызова:
//
//        cleanup := InitTracer(cfg)
//        defer cleanup()
func InitTracer(cfg Config) func() <span class="cov0" title="0">{

        ctx := context.Background()

        // Создание экспортера OTLP gRPC для отправки данных в OpenTelemetry Collector
        // Создаем OTLP gRPC экспортер для трассировок
        exporter, err := otlptracegrpc.New(ctx,
                otlptracegrpc.WithInsecure(),                      // Без TLS (используйте WithTLS() для включения)
                otlptracegrpc.WithEndpoint(cfg.CollectorEndpoint), // Адрес OpenTelemetry Collector
        )

        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("Ошибка создания OTLP gRPC экспортера: %v", err)
        }</span>

        // Создание BatchSpanProcessor
        <span class="cov0" title="0">batchProcessor := trace.NewBatchSpanProcessor(
                exporter,
                trace.WithBatchTimeout(cfg.BatchTimeout), // Отправлять каждые 5 секунд
                trace.WithMaxExportBatchSize(cfg.MaxExportBatchSize), // Не более MaxExportBatchSize спанов за раз
                trace.WithMaxQueueSize(cfg.MaxQueueSize),             // Максимум MaxQueueSize спанов в очереди
        )

        // Оборачиваем BatchSpanProcessor фильтрующим процессором
        filteringProcessor := &amp;filteringSpanProcessor{next: batchProcessor}

        // Настраиваем TracerProvider
        tp := trace.NewTracerProvider(
                trace.WithSpanProcessor(filteringProcessor),
                trace.WithResource(resource.NewSchemaless(
                        semconv.ServiceNameKey.String(cfg.ServiceName),
                )),
        )
        otel.SetTracerProvider(tp)
        otel.SetTextMapPropagator(propagation.TraceContext{})

        return func() </span><span class="cov0" title="0">{
                if err := tp.Shutdown(ctx); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("failed to shutdown TracerProvider: %v", err)
                }</span>
        }
}

// InitSimpleTracer Пример инициализации трассировщика с консольным экспортером:
func InitSimpleTracer() func() <span class="cov0" title="0">{
        // Создаем экспортер для вывода трассировок в консоль
        exporter, err := stdouttrace.New(stdouttrace.WithPrettyPrint())
        if err != nil </span><span class="cov0" title="0">{
                log.Fatalf("failed to initialize stdouttrace exporter: %v", err)
        }</span>

        // Создаем TracerProvider с экспортёром
        <span class="cov0" title="0">tp := trace.NewTracerProvider(
                trace.WithBatcher(exporter), // Отправка данных в экспортер
                trace.WithResource(resource.NewSchemaless(
                        attribute.String("service.name", "example-service"),
                )),
        )

        // Устанавливаем глобальный TracerProvider
        otel.SetTracerProvider(tp)

        // Возвращаем функцию для завершения работы TracerProvider
        return func() </span><span class="cov0" title="0">{
                if err := tp.Shutdown(context.Background()); err != nil </span><span class="cov0" title="0">{
                        log.Fatalf("failed to shutdown TracerProvider: %v", err)
                }</span>
        }
}

// Для фильтрации спанов
type filteringSpanProcessor struct {
        next trace.SpanProcessor
}

func (fsp *filteringSpanProcessor) OnStart(parent context.Context, span trace.ReadWriteSpan) <span class="cov0" title="0">{
        fsp.next.OnStart(parent, span)
}</span>

// OnEnd Здесь настраиваем фильтры по названию спана
// Пропускаем спаны, связанные с Docker API
func (fsp *filteringSpanProcessor) OnEnd(span trace.ReadOnlySpan) <span class="cov0" title="0">{
        if strings.Contains(span.Name(), "/containers") ||
                strings.Contains(span.Name(), "GET /") ||
                strings.Contains(span.Name(), "HEAD /") </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">fsp.next.OnEnd(span)</span>
}

func (fsp *filteringSpanProcessor) Shutdown(ctx context.Context) error <span class="cov0" title="0">{
        return fsp.next.Shutdown(ctx)
}</span>

func (fsp *filteringSpanProcessor) ForceFlush(ctx context.Context) error <span class="cov0" title="0">{
        return fsp.next.ForceFlush(ctx)
}</span>
</pre>
		
		<pre class="file" id="file20" style="display: none">// Package utils getting the path to the current project directory
// If your application can be launched not from the root folder of the project,
// then you can use a known file or directory in the root folder to count the path relative to it.
package utils

import (
        "fmt"
        "os"
        "path/filepath"
)

// GetProjectRoot getting the root directory of the project from the "anchor" file (a known file in the root directory)
func GetProjectRoot(anchorFile string) (string, error) <span class="cov1" title="1">{
        // Suppose there is a file in the root folder, for example "go.mod"
        currentDir, err := os.Getwd()
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>

        <span class="cov1" title="1">for </span><span class="cov10" title="3">{
                if _, err := os.Stat(filepath.Join(currentDir, anchorFile)); err == nil </span><span class="cov1" title="1">{
                        return currentDir, nil
                }</span>

                <span class="cov6" title="2">parentDir := filepath.Dir(currentDir)
                if parentDir == currentDir </span><span class="cov0" title="0">{
                        // We reached the root of the file system and did not find "go.mod"
                        break</span>
                }
                <span class="cov6" title="2">currentDir = parentDir</span>
        }
        <span class="cov0" title="0">return "", fmt.Errorf("the root folder of the project could not be found")</span>
}
</pre>
		
		<pre class="file" id="file21" style="display: none">package testcontainers

import (
        "context"
        "fmt"
        "strings"
        "testing"

        "github.com/testcontainers/testcontainers-go"
        "github.com/testcontainers/testcontainers-go/modules/kafka"
)

func NewKafkaTestcontainer(t *testing.T) (*kafka.KafkaContainer, error) <span class="cov10" title="2">{
        ctx := context.Background()
        kafkaContainer, err := kafka.Run(ctx, "confluentinc/confluent-local:7.5.0", kafka.WithClusterID("testCluster"))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov10" title="2">testcontainers.CleanupContainer(t, kafkaContainer)

        if !strings.EqualFold(kafkaContainer.ClusterID, "testCluster") </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("expected clusterID to be %s, got %s", "testCluster", kafkaContainer.ClusterID)
        }</span>

        <span class="cov10" title="2">return kafkaContainer, nil</span>
}
</pre>
		
		<pre class="file" id="file22" style="display: none">package testcontainers

import (
        "context"
        "testing"
        "time"

        "github.com/testcontainers/testcontainers-go"
        "github.com/testcontainers/testcontainers-go/modules/postgres"
        "github.com/testcontainers/testcontainers-go/wait"
)

func NewPostgresTestcontainer(t *testing.T) (*postgres.PostgresContainer, error) <span class="cov10" title="2">{
        ctx := context.Background()
        postgresContainer, err := postgres.Run(ctx, "postgres:16-alpine",
                testcontainers.WithWaitStrategy(
                        wait.ForLog("database system is ready to accept connections").
                                WithOccurrence(2).
                                WithStartupTimeout(5*time.Second)),
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov10" title="2">testcontainers.CleanupContainer(t, postgresContainer)

        return postgresContainer, nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
